{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data RDM Creatation and Model Comparison Notebook\n",
    "\n",
    "*More complicated script*\n",
    "\n",
    "This script constructs a data RDM for each searchlight sphere. i.e. there is a `RDMs` object for each searchlight.\n",
    "\n",
    "Steps for analysis. \n",
    "\n",
    "1. Get the correct directory for the analysis\n",
    "2. Create the searchlight (composed of centers and neighbors)\n",
    "   1. From the mask of the functional parts of the brain. The preprocess part of the brain that corresponds to doing computation. \n",
    "3. Load in the EVs that correspond to the correct parts of the BOLD video of the participant doing the task. \n",
    "   - i.e. The periods of time (in the BOLD video) that are part of the instruction period of the task.\n",
    "   - Then load in the EVs, using nibabel, into np.arrays for each instruction period of the task for each half of the task \n",
    "4. Create the RDMs for each searchlight for the data of the participant. \n",
    "   This will return a object `data_RDMs` that contains the `RDMs` for each searchlight that was created in step 2. \n",
    "5. Compute the similarity between the `RDMs` of that we defined and compared it to every searchlight `RDMs` in the data.\n",
    "\n",
    "\n",
    "OPTIONS: \n",
    "1. Subject number\n",
    "2. EVs in question (\"instruction_period\")\n",
    "3. RDM type (\"replay_analysis\")\n",
    "4. Remove autocorrelation between task half \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatically reload modules that have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# RSA specific libraries\n",
    "import nibabel as nib\n",
    "from nilearn.image import load_img\n",
    "import rsatoolbox.rdm as rsr\n",
    "import rsatoolbox.vis as vis\n",
    "import rsatoolbox\n",
    "from rsatoolbox.rdm import RDMs\n",
    "from rsatoolbox.util.searchlight import get_volume_searchlight, get_searchlight_RDMs\n",
    "\n",
    "# mc imports\n",
    "import mc.analyse.analyse_MRI_behav     as analyse_MRI_behav\n",
    "import mc.analyse.calc                  as calc\n",
    "import mc.replay_analysis.functions.model_rdms as model_rdm_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "REGRESSION_VERSION = '01' \n",
    "RDM_VERSION        = '01-2' \n",
    "SUB_NO = '01'\n",
    "\n",
    "\n",
    "USE_PREVIOUS_SEARCHLIGHTS = True  # Searchlights are loaded from file\n",
    "USE_PREVIOUS_DATA_RDM     = False # Data RDMs are loaded from file\n",
    "VISUALISE_RDMS            = False # Visualise the data RDMs\n",
    "REMOVE_AUTOCORR           = True  # Remove autocorrelations from the data RDMs, else cross-correlate\n",
    "EVS_TYPE                  = \"instruction_period\"     # The parts of the BOLD signal that are used for the RSA\n",
    "\n",
    "# Paths\n",
    "data_folder = Path('/Users/student/PycharmProjects/data')\n",
    "\n",
    "# Subjects to be analysed\n",
    "sub: str = f\"sub-{SUB_NO}\"\n",
    "#subjects = ['sub-01']\n",
    "task_halves: list = ['1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running RSA for RDM version 01-2 based on subj GLM 01 for subj 01\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now running RSA for RDM version {RDM_VERSION} based on subj GLM {REGRESSION_VERSION} for subj {SUB_NO}\")\n",
    "\n",
    "# get the list of the models to be analysed\n",
    "models_I_want: list = analyse_MRI_behav.models_I_want(RDM_VERSION)\n",
    "\n",
    "# based on GLM, get the number of conditions in the RDM\n",
    "no_RDM_conditions: int = analyse_MRI_behav.get_no_RDM_conditions(RDM_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the correct directory for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/student/PycharmProjects/data/derivatives/sub-01\n",
      "Running on laptop.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subject_directory = data_folder / 'derivatives' / sub\n",
    "print(subject_directory)\n",
    "if os.path.isdir(subject_directory):\n",
    "    print(\"Running on laptop.\")\n",
    "\n",
    "\n",
    "RDM_dir = subject_directory / 'beh' / f\"RDMs_{RDM_VERSION}_glmbase_{REGRESSION_VERSION}\"\n",
    "\n",
    "\n",
    "# Make the RDM_dir if it doesn't exist\n",
    "if not RDM_dir.exists():\n",
    "    RDM_dir.mkdir(parents=True)\n",
    "results_dir = subject_directory / 'func' / f\"RSA_{RDM_VERSION}_glmbase_{REGRESSION_VERSION}\"\n",
    "\n",
    "# Make the results_dir if it doesn't exist\n",
    "# if not results_dir.exists():\n",
    "#     results_dir.mkdir(parents=True)\n",
    "#     os.makedirs(f\"{results_dir}/results\")\n",
    "# results_dir = f\"{subject_directory}/func/RSA_{RDM_VERSION}_glmbase_{REGRESSION_VERSION}/results\" \n",
    "# if os.path.exists(results_dir):\n",
    "#     # move pre-existing files into a different folder.\n",
    "#     analyse_MRI_behav.move_files_to_subfolder(results_dir)\n",
    "# get a reference image to later project the results onto. This is usually\n",
    "# example_func from half 1, as this is where the data is corrected to.\n",
    "\n",
    "# results_dir = results_dir / 'results' \n",
    "ref_img = load_img( subject_directory / 'func' / 'preproc_clean_01.feat'/ 'example_func.nii.gz' )\n",
    "\n",
    "# load the file which defines the order of the model RDMs, and hence the data RDMs\n",
    "with open(f\"{RDM_dir}/sorted_keys-model_RDMs.pkl\", 'rb') as file:\n",
    "    sorted_keys = pickle.load(file)\n",
    "with open(f\"{RDM_dir}/sorted_regs.pkl\", 'rb') as file:\n",
    "    reg_keys = pickle.load(file)\n",
    "# also store 2 dictionaries of the EVs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "REGRESSION_VERSION = analyse_MRI_behav.preprocess_regression_version(REGRESSION_VERSION)\n",
    "\n",
    "# create dictionary of paths to the EVs for each half (split) of the task\n",
    "# first half\n",
    "EV_path_dict_01 = analyse_MRI_behav.get_EV_dict(\n",
    "    subject_directory, REGRESSION_VERSION\n",
    "    )\n",
    "# second half\n",
    "EV_path_dict_02 = analyse_MRI_behav.get_EV_dict(\n",
    "    subject_directory, REGRESSION_VERSION\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the search lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: get the searchlights\n",
    "\n",
    "# Load the functional mask of the subject (i.e. the brain mask of only the computation parts of the brain)\n",
    "mask = load_img(f\"{subject_directory}/anat/{sub}_T1w_noCSF_brain_mask_bin_func_01.nii.gz\")\n",
    "\n",
    "# Get the searchlights\n",
    "centers, neighbors = model_rdm_functions.get_searchlights(\n",
    "    mask = mask,\n",
    "    radius = 3, \n",
    "    threshold = 0.5,\n",
    "    USE_PREVIOUS_SEARCHLIGHTS = USE_PREVIOUS_SEARCHLIGHTS,\n",
    "    NEIGHBORS_PATH=f\"{RDM_dir}/searchlight_neighbors.pkl\",\n",
    "    CENTERS_PATH=f\"{RDM_dir}/searchlight_centers.pkl\",\n",
    "    SAVE_SEARCHLIGHTS = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the correct EVs from the BOLD video\n",
    "(for the participant). This comes from a proprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: loading and computing the data RDMs\n",
    "if USE_PREVIOUS_DATA_RDM == True:\n",
    "    # Open the data RDM file\n",
    "    with open(f\"{results_dir}/data_RDM.pkl\", 'rb') as file:\n",
    "        data_RDM = pickle.load(file)\n",
    "    \n",
    "    if VISUALISE_RDMS == True:\n",
    "        analyse_MRI_behav.visualise_data_RDM(mni_x = 53, \n",
    "                                             mni_y = 30, \n",
    "                                             mni_z = 2, \n",
    "                                             data_RDM_file = data_RDM, \n",
    "                                             mask = mask)\n",
    "        \n",
    "else:\n",
    "    # Create dictionary to store the data for each EV for both task halves\n",
    "    EVs_both_halves_dict = {\n",
    "        '1': None,\n",
    "        '2': None\n",
    "    }\n",
    "    # create new dictionary to store the 2D array of EVs for both task halves\n",
    "    EVs_both_halves_2d = EVs_both_halves_dict.copy()\n",
    "\n",
    "    for split in task_halves:\n",
    "\n",
    "        \n",
    "        EVs_path_dict = model_rdm_functions.get_EV_path_dict(\n",
    "            subject_directory = subject_directory,\n",
    "            split = split,\n",
    "            EVs_type = EVS_TYPE\n",
    "            )\n",
    "        \n",
    "        # Load in the EVs for the instruction periods from the dictionary of paths\n",
    "        EVs_data_dict = model_rdm_functions.load_EV_data(\n",
    "            EVs_path_dict = EVs_path_dict,\n",
    "            RDM_VERSION = RDM_VERSION\n",
    "        )\n",
    "\n",
    "        # Convert the dictionary of EVs to a 2D np.array (10 * 746496) (10 conditions, 746496 voxels)\n",
    "        EVs_data_2d = model_rdm_functions.EV_data_dict_to_2d(\n",
    "            EVs_data_dict = EVs_data_dict,\n",
    "        )\n",
    "        \n",
    "        # Put the 2D array of EVs into the EV_both_halves dictionary\n",
    "        EVs_both_halves_dict[split] = EVs_data_dict\n",
    "        EVs_both_halves_2d  [split] = EVs_data_2d\n",
    "\n",
    "        # Each part has array of shape (n_conditions, x, y, z)\n",
    "        EVs_both_halves_dict[split] = np.array(list(EVs_both_halves_dict[split].values()))\n",
    "        # Remove NaNs\n",
    "        EVs_both_halves_dict[split] = np.nan_to_num(EVs_both_halves_dict[split])\n",
    "\n",
    "        # Each part has array of shape (n_conditions, n_voxels)\n",
    "        EVs_both_halves_2d[split] = EVs_both_halves_dict[split].reshape(EVs_both_halves_dict[split].shape[0], -1)\n",
    "\n",
    "    # Combine the EVs from both task halves into a single 2D array (condition, x, y, z)\n",
    "    EVs_both_halves_array_2d = np.concatenate((EVs_both_halves_2d['1'], EVs_both_halves_2d['2']), axis=0)\n",
    "\n",
    "    # Remove NaNs\n",
    "    # EVs_both_halves_array_2d = np.nan_to_num(EVs_both_halves_array_2d)\n",
    "\n",
    "    # define the condition names for both task halves\n",
    "    # 2 * 10 conditions, since there are 10 identical executution conditions in each task half\n",
    "    # data_conds = np.reshape(np.tile((np.array(['cond_%02d' % x for x in np.arange(no_RDM_conditions)])), (1, 2)).transpose(), 2 * no_RDM_conditions)\n",
    "    data_conds = [x for x in range(20)]\n",
    "    # data_conds = np.reshape(np.tile((np.array(['cond_%02d' % x for x in np.arange(no_RDM_conditions)])), (1)).transpose(), no_RDM_conditions)\n",
    "\n",
    "    # Defining both task halves runs: 0s first half, 1s is second half\n",
    "    sessions = np.concatenate((np.zeros(int(EVs_both_halves_2d['1'].shape[0])),   # 10 of each condition\n",
    "                                np.ones(int(EVs_both_halves_2d['2'].shape[0]))))  # 10 of each condition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the RDMs for each searchlight in the \n",
    "*Takes a while*\n",
    "This function returns a `data_RDMs` object that contains the RDM matrix for each searchlight (centers, neighbors) in the BOLD video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating RDMs...:  39%|███▉      | 39/100 [00:10<00:15,  3.95it/s]/Users/student/anaconda3/envs/rsa/lib/python3.11/site-packages/rsatoolbox/rdm/calc.py:217: RuntimeWarning: invalid value encountered in divide\n",
      "  ma /= np.sqrt(np.einsum('ij,ij->i', ma, ma))[:, None]\n",
      "Calculating RDMs...: 100%|██████████| 100/100 [00:26<00:00,  3.83it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# for all other cases, cross correlated between task-halves.\n",
    "# TODO: try to have one only half \n",
    "data_RDM = get_searchlight_RDMs(\n",
    "    # data_2d = EVs_both_halves_2d,         # (nObs x nVox) (20 * 746496)\n",
    "    data_2d = EVs_both_halves_array_2d, # (nObs x nVox)\n",
    "    centers = centers, \n",
    "    neighbors = neighbors, \n",
    "    events  = data_conds,                 # (nObs x 1) of condition labels (con§d_00, cond_01, ... cond_09)\n",
    "    method = 'correlation', \n",
    "    # method  ='crosscorr', \n",
    "    # cv_descr = sessions                   # (nObs x 1) of session labels (0, 1)\n",
    "                )\n",
    "\n",
    "# Save the data RDMs\n",
    "with open(f\"{results_dir}/data_RDM.pkl\", 'wb') as file:\n",
    "    pickle.dump(data_RDM, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Model RDMs object from previous script\n",
    "For Alif's implementation, the Model RDMs will be already created from the \"vector\" models of the data that are created in previous model RDM script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 3: Load  Model RDMs, created in `replay_RSA_model_RDM.py`\n",
    "# RDM_object_dict = {}\n",
    "\n",
    "# RDM_object_dict['replay'] = model_rdm_functions.load_model_RDMs(\n",
    "#     RDM_dir = RDM_dir,\n",
    "    \n",
    "#     )\n",
    "\n",
    "# model_RDM_dict = {}\n",
    "# Step 4: Run the RSA\n",
    "# model_RDM_dict[\"replay\"] = rsr.calc_rdm(\n",
    "#     dataset = replay_RDM_object, \n",
    "#     method='correlation', \n",
    "#     descriptor='conds'\n",
    "#     )\n",
    "\n",
    "\n",
    "replay_dir = \"/Users/student/PycharmProjects/data/derivatives/sub-01/beh/RDMs_01_glmbase_01/replay_RDM_object.pkl\"\n",
    "\n",
    "with open(replay_dir, 'rb') as file:\n",
    "    replay_RDM_object = pickle.load(file)\n",
    "\n",
    "# data_RDM = model_rdm_functions.load_model_RDMs(replay_dir)\n",
    "# print(\"Running RSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Step 4: Create Fixed Model RDMs\n",
    "# def prepare_model_RDM_dict(\n",
    "#     model_RDMs: dict,\n",
    "#     no_RDM_conditions: int,\n",
    "#     RDM_VERSION: str,\n",
    "#     MODEL_TYPE: str = \"matrix\",\n",
    "#     VISUALISE_RDMS: bool = False,\n",
    "#     REMOVE_AUTOCORR: bool = True\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Parameters\n",
    "#         neuron_model_RDMs: dictionary of model RDMs\n",
    "#         no_RDM_conditions: number of conditions in the RDM\n",
    "#         RDM_VERSION: version of the RDM\n",
    "#         MODEL_TYPE: \"neuron\" represent the vector form of the model RDM. \"matrix\" represents the matrix form of the model RDM\n",
    "#         REMOVE_AUTOCORR: remove autocorrelations from the model RDMs. If True it takes into account to the two task halves\n",
    "\n",
    "#     Returns\n",
    "#         model_RDM_dir: dict Dictionary of model RDMs\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Where, each model gets its own, separate estimation.\n",
    "#     model_RDM_dir = {}\n",
    "\n",
    "#     if MODEL_TYPE == \"neuron\":\n",
    "#         # Use the vectors for the different conditions to create the RDMs\n",
    "\n",
    "#         for model in model_RDMs:\n",
    "#             # 4.1 either prepare the neuron_modlel and place it into the `analyse_MRI_behav.prepare_model_data function`, then run the `rsr.calc_rdm` function\n",
    "#             # prepare the neuron_model of the data into the Dataset object that is used in rsr.calc_rdm()\n",
    "#             model_data = analyse_MRI_behav.prepare_model_data(\n",
    "#                 model_RDMs[model],\n",
    "#                 no_RDM_conditions,\n",
    "#                 RDM_VERSION)\n",
    "            \n",
    "#             if REMOVE_AUTOCORR == False:\n",
    "#                 # assumes that both task halves are one session\n",
    "#                 model_RDM_dir[model] = rsr.calc_rdm(\n",
    "#                     model_data, \n",
    "#                     method='correlation', \n",
    "#                     descriptor='conds'\n",
    "#                     )\n",
    "\n",
    "#             else:\n",
    "#                 # assumes that there are two task halves, that need to be corrected for autocorrelations\n",
    "#                 model_RDM_dir[model] = rsr.calc_rdm(\n",
    "#                     model_data, \n",
    "#                     method='crosscorr', \n",
    "#                     descriptor='conds', \n",
    "#                     cv_descriptor='sessions'\n",
    "#                     )\n",
    "\n",
    "#     elif MODEL_TYPE == \"matrix\":\n",
    "#         # takes a dictionary of matrix RDMs as the correctly packaged into the RDMs object in a dictionary\n",
    "\n",
    "#         for model in model_RDMs:\n",
    "            \n",
    "#             # get the model from the model_RDMs dictionary\n",
    "#             model_RDM = model_RDMs[model]\n",
    "\n",
    "#             if REMOVE_AUTOCORR == False:\n",
    "#                 model_RDM_dir[model] = rsr.calc_rdm(\n",
    "#                     dataset = model_RDM,\n",
    "#                     method = 'correlation',\n",
    "#                     descriptor = 'conds'\n",
    "#                 )\n",
    "            \n",
    "#             else: \n",
    "#                 model_RDM_dir[model] = rsr.calc_rdm(\n",
    "#                     dataset = model_RDM,\n",
    "#                     method = 'crosscorr',\n",
    "#                     descriptor = 'conds',\n",
    "#                     cv_descriptor = 'sessions'\n",
    "#                 )\n",
    "\n",
    "#     if VISUALISE_RDMS == True:\n",
    "#         # Visualise the model RDMs\n",
    "#         fig, ax, ret_vla = rsatoolbox.vis.show_rdm(model_RDM_dir[model])\n",
    "\n",
    "\n",
    "#     return model_RDM_dir\n",
    "\n",
    "# # Prepare the model RDMs\n",
    "# model_RDM_dict = prepare_model_RDM_dict(\n",
    "#     model_RDMs = neuron_model_RDMs,\n",
    "#     no_RDM_conditions = no_RDM_conditions,\n",
    "#     RDM_VERSION = RDM_VERSION,\n",
    "#     MODEL_TYPE = \"neuron\",\n",
    "#     VISUALISE_RDMS = VISUALISE_RDMS,\n",
    "#     REMOVE_AUTOCORR = REMOVE_AUTOCORR\n",
    "# )\n",
    "\n",
    "\n",
    "# def run_fixed_model(\n",
    "#     model_RDM_dir: dict\n",
    "# ):\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Step 4.2: evaluate the model fit between model and data RDMs.\n",
    "#     \"\"\"\n",
    "#     # Dictionary to store the results\n",
    "#     RDM_my_model_dir = {}\n",
    "\n",
    "#     for model in model_RDM_dir:\n",
    "#         # Define the type of model to be evaluated. It is a single model, not a set of models that. It does not have a set of betas to also fit. \n",
    "#         single_model = rsatoolbox.model.ModelFixed(f\"{model}_only\", model_RDM_dir[model])\n",
    "#         # Run the model evaluation for all searchlights\n",
    "#         RDM_my_model_dir[model] = Parallel(n_jobs=3)(delayed(analyse_MRI_behav.evaluate_model)(single_model, data_RDM_p_voxel) for data_RDM_p_voxel in tqdm(data_RDM, desc=f\"running GLM for all searchlights in {model}\"))\n",
    "        \n",
    "\n",
    "#     # return dictionary of results\n",
    "#     return RDM_my_model_dir\n",
    "\n",
    "\n",
    "# # Run the fixed model\n",
    "# RDM_my_model_dir = run_fixed_model(\n",
    "#     model_RDM_dir = model_RDM_dict\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RDMs' object has no attribute 'transpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(replay_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m     replay_RDM_object \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m----> 8\u001b[0m model_RDM_object \u001b[38;5;241m=\u001b[39m \u001b[43manalyse_MRI_behav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_model_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreplay_RDM_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_Conditions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mno_RDM_conditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRDM_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m01\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/Music-Box-fMRI/multiple_clocks_repo/mc/analyse/analyse_MRI_behav.py:630\u001b[0m, in \u001b[0;36mprepare_model_data\u001b[0;34m(model_data, no_Conditions, RDM_version)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m        The object contains the model data in the correct format for the RSA analysis.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m model_data \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# Get the number of conditions \u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RDM_version \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01-1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01-2\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RDMs' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "replay_dir = \"/Users/student/PycharmProjects/data/derivatives/sub-01/beh/RDMs_01_glmbase_01/replay_RDM_object.pkl\"\n",
    "with open(replay_dir, 'rb') as file:\n",
    "    replay_RDM_object = pickle.load(file)\n",
    "\n",
    "\n",
    "model_RDM_object = analyse_MRI_behav.prepare_model_data(\n",
    "    model_data = replay_RDM_object,\n",
    "    no_Conditions = no_RDM_conditions,\n",
    "    RDM_version= \"01\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that the single_model.__dict__ is a readout of the model RDM object. This should match formatting of the data RDMs object. (`data_RDM_p_voxel`). \n",
    "These are the things being compared so they ahve to match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'replay_only',\n",
       " 'n_param': 0,\n",
       " 'default_fitter': <function rsatoolbox.model.fitter.fit_mock(model, data, method='cosine', pattern_idx=None, pattern_descriptor=None, sigma_k=None)>,\n",
       " 'rdm_obj': rsatoolbox.rdm.RDMs(\n",
       " dissimilarity_measure = \n",
       " Arbitrary\n",
       " dissimilarities = \n",
       " [[-1.    0.25  0.    0.25  0.    0.25  0.    0.25  0.    0.    1.   -0.25\n",
       "    0.   -0.25  0.   -0.25  0.   -0.25  0.    0.    0.25  0.    0.25  0.\n",
       "    0.25  0.    0.25  1.    0.    0.   -0.25  0.   -0.25  0.   -0.25  0.\n",
       "   -0.25 -1.    0.25  0.    0.25  0.    0.25  0.   -0.25  0.    0.    1.\n",
       "   -0.25  0.   -0.25  0.   -0.25  0.    0.    0.25  0.    0.25  0.    0.25\n",
       "    0.   -0.25  1.    0.    0.   -0.25  0.   -0.25  0.   -0.25 -1.    0.25\n",
       "    0.    0.25  0.   -0.25  0.   -0.25  0.    0.    1.   -0.25  0.   -0.25\n",
       "    0.    0.    0.25  0.    0.25  0.   -0.25  0.   -0.25  1.    0.    0.\n",
       "   -0.25  0.   -0.25 -1.    0.25  0.   -0.25  0.   -0.25  0.   -0.25  0.\n",
       "    0.    1.   -0.25  0.    0.    0.25  0.   -0.25  0.   -0.25  0.   -0.25\n",
       "    1.    0.    0.   -0.25 -1.   -0.25  0.   -0.25  0.   -0.25  0.   -0.25\n",
       "    0.    0.    1.    0.   -0.25  0.   -0.25  0.   -0.25  0.   -0.25  1.\n",
       "    0.   -1.    0.25  0.    0.25  0.    0.25  0.    0.25  0.    0.    0.25\n",
       "    0.    0.25  0.    0.25  0.    0.25 -1.    0.25  0.    0.25  0.    0.25\n",
       "    0.    0.    0.25  0.    0.25  0.    0.25 -1.    0.25  0.    0.25  0.\n",
       "    0.    0.25  0.    0.25 -1.    0.25  0.    0.    0.25 -1.  ]]\n",
       " descriptors = \n",
       " {'replay': 'Replay Model'}\n",
       " rdm_descriptors = \n",
       " {'index': [0]}\n",
       " pattern_descriptors = \n",
       " {'index': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19])},\n",
       " 'rdm': array([-1.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,  0.  ,\n",
       "         0.  ,  1.  , -0.25,  0.  , -0.25,  0.  , -0.25,  0.  , -0.25,\n",
       "         0.  ,  0.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,\n",
       "         1.  ,  0.  ,  0.  , -0.25,  0.  , -0.25,  0.  , -0.25,  0.  ,\n",
       "        -0.25, -1.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,  0.  , -0.25,\n",
       "         0.  ,  0.  ,  1.  , -0.25,  0.  , -0.25,  0.  , -0.25,  0.  ,\n",
       "         0.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,  0.  , -0.25,  1.  ,\n",
       "         0.  ,  0.  , -0.25,  0.  , -0.25,  0.  , -0.25, -1.  ,  0.25,\n",
       "         0.  ,  0.25,  0.  , -0.25,  0.  , -0.25,  0.  ,  0.  ,  1.  ,\n",
       "        -0.25,  0.  , -0.25,  0.  ,  0.  ,  0.25,  0.  ,  0.25,  0.  ,\n",
       "        -0.25,  0.  , -0.25,  1.  ,  0.  ,  0.  , -0.25,  0.  , -0.25,\n",
       "        -1.  ,  0.25,  0.  , -0.25,  0.  , -0.25,  0.  , -0.25,  0.  ,\n",
       "         0.  ,  1.  , -0.25,  0.  ,  0.  ,  0.25,  0.  , -0.25,  0.  ,\n",
       "        -0.25,  0.  , -0.25,  1.  ,  0.  ,  0.  , -0.25, -1.  , -0.25,\n",
       "         0.  , -0.25,  0.  , -0.25,  0.  , -0.25,  0.  ,  0.  ,  1.  ,\n",
       "         0.  , -0.25,  0.  , -0.25,  0.  , -0.25,  0.  , -0.25,  1.  ,\n",
       "         0.  , -1.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,\n",
       "         0.  ,  0.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,\n",
       "        -1.  ,  0.25,  0.  ,  0.25,  0.  ,  0.25,  0.  ,  0.  ,  0.25,\n",
       "         0.  ,  0.25,  0.  ,  0.25, -1.  ,  0.25,  0.  ,  0.25,  0.  ,\n",
       "         0.  ,  0.25,  0.  ,  0.25, -1.  ,  0.25,  0.  ,  0.  ,  0.25,\n",
       "        -1.  ]),\n",
       " 'n_cond': 20}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replay_RDM_object\n",
    "single_model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rsatoolbox.rdm.RDMs(\n",
       "dissimilarity_measure = \n",
       "crosscorr\n",
       "dissimilarities = \n",
       "[[1.18280327 1.03554441 1.16859723 0.83408911 1.18755462 1.19309875\n",
       "  1.06420735 1.14512869 1.09228604 0.35876889 0.42071846 0.83255953\n",
       "  0.49742841 0.91828871 0.35357708 0.48662118 0.78141249 1.3330743\n",
       "  1.42478664 1.29528497 1.13690648 1.28888624 1.06374565 1.15682004\n",
       "  0.78523534 0.34180407 0.95716977 0.386003   0.32168538 0.73678456\n",
       "  1.14594754 1.19582381 1.17198995 1.00953275 0.98233452 1.301615\n",
       "  1.3696185  1.38305538 0.95839203 0.95554143 0.67282555 1.00517554\n",
       "  0.48016354 0.68537069 1.14973713]]\n",
       "descriptors = \n",
       "{}\n",
       "rdm_descriptors = \n",
       "{'voxel_index': [162003], 'index': [0]}\n",
       "pattern_descriptors = \n",
       "{'index': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single_model.rdm.shape, replay_RDM_object.dissimilarities.shape \n",
    "data_RDM_p_voxel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model RDMs with the data RDMs\n",
    "For the evaluation function to work, we need to the model and data RDMs need to be in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running GLM for all searchlights in replay: 100%|██████████| 172178/172178 [00:09<00:00, 18636.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the results\n",
    "RDM_my_model_dir = {}\n",
    "# Define the type of model to be evaluated. It is a single model, not a set of models that. It does not have a set of betas to also fit. \n",
    "model = \"replay\"\n",
    "single_model = rsatoolbox.model.ModelFixed(f\"{model}_only\", replay_RDM_object)\n",
    "\n",
    "# Run the model evaluation for all searchlights\n",
    "RDM_my_model_dir[model] = Parallel(n_jobs=3)(delayed(analyse_MRI_behav.evaluate_model)(single_model, data_RDM_p_voxel) for data_RDM_p_voxel in tqdm(data_RDM, desc=f\"running GLM for all searchlights in {model}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(RDM_my_model_dir[model][0][0])\n",
    "RDM_my_model_dir[model][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4.3: Save the results\n",
    "for model in RDM_my_model_dir:\n",
    "    # Save the different aspects of the model as different nii files \n",
    "    analyse_MRI_behav.save_RSA_result(\n",
    "                        result_file = RDM_my_model_dir[model], \n",
    "                        data_RDM_file = data_RDM, \n",
    "                        file_path = results_dir, \n",
    "                        file_name = f\"{model}\", \n",
    "                        mask = mask, \n",
    "                        number_regr = 0, \n",
    "                        ref_image_for_affine_path=ref_img\n",
    "                        )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
